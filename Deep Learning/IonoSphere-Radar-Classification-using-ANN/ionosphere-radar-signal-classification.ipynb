{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/uci-ionosphere/ionosphere_data_kaggle.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv(\"../input/uci-ionosphere/ionosphere_data_kaggle.csv\",delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature26</th>\n",
       "      <th>feature27</th>\n",
       "      <th>feature28</th>\n",
       "      <th>feature29</th>\n",
       "      <th>feature30</th>\n",
       "      <th>feature31</th>\n",
       "      <th>feature32</th>\n",
       "      <th>feature33</th>\n",
       "      <th>feature34</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
       "0         1         0   0.99539  -0.05889   0.85243   0.02306   0.83398   \n",
       "1         1         0   1.00000  -0.18829   0.93035  -0.36156  -0.10868   \n",
       "2         1         0   1.00000  -0.03365   1.00000   0.00485   1.00000   \n",
       "3         1         0   1.00000  -0.45161   1.00000   1.00000   0.71216   \n",
       "4         1         0   1.00000  -0.02401   0.94140   0.06531   0.92106   \n",
       "\n",
       "   feature8  feature9  feature10  ...  feature26  feature27  feature28  \\\n",
       "0  -0.37708   1.00000    0.03760  ...   -0.51171    0.41078   -0.46168   \n",
       "1  -0.93597   1.00000   -0.04549  ...   -0.26569   -0.20468   -0.18401   \n",
       "2  -0.12062   0.88965    0.01198  ...   -0.40220    0.58984   -0.22145   \n",
       "3  -1.00000   0.00000    0.00000  ...    0.90695    0.51613    1.00000   \n",
       "4  -0.23255   0.77152   -0.16399  ...   -0.65158    0.13290   -0.53206   \n",
       "\n",
       "   feature29  feature30  feature31  feature32  feature33  feature34  label  \n",
       "0    0.21266   -0.34090    0.42267   -0.54487    0.18641   -0.45300      g  \n",
       "1   -0.19040   -0.11593   -0.16626   -0.06288   -0.13738   -0.02447      b  \n",
       "2    0.43100   -0.17365    0.60436   -0.24180    0.56045   -0.38238      g  \n",
       "3    1.00000   -0.20099    0.25682    1.00000   -0.32382    1.00000      b  \n",
       "4    0.02431   -0.62197   -0.05707   -0.59573   -0.04608   -0.65697      g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature1     0\n",
       "feature2     0\n",
       "feature3     0\n",
       "feature4     0\n",
       "feature5     0\n",
       "feature6     0\n",
       "feature7     0\n",
       "feature8     0\n",
       "feature9     0\n",
       "feature10    0\n",
       "feature11    0\n",
       "feature12    0\n",
       "feature13    0\n",
       "feature14    0\n",
       "feature15    0\n",
       "feature16    0\n",
       "feature17    0\n",
       "feature18    0\n",
       "feature19    0\n",
       "feature20    0\n",
       "feature21    0\n",
       "feature22    0\n",
       "feature23    0\n",
       "feature24    0\n",
       "feature25    0\n",
       "feature26    0\n",
       "feature27    0\n",
       "feature28    0\n",
       "feature29    0\n",
       "feature30    0\n",
       "feature31    0\n",
       "feature32    0\n",
       "feature33    0\n",
       "feature34    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input vector and output vector\n",
    "X = data.values[1:,0:34].astype(float)\n",
    "Y = data.values[1:,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(34, input_dim=34 , activation= 'relu' ))\n",
    "# Adding dropout to prevent overfitting\n",
    "model.add(Dropout(p=0.1))\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "# Adding dropout to prevent overfitting\n",
    "model.add(Dropout(p=0.1))\n",
    "model.add(Dense(1,  activation= 'sigmoid' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "epochs = 50\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(loss= 'binary_crossentropy' , optimizer=sgd, metrics=[ 'accuracy' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 187 samples, validate on 93 samples\n",
      "Epoch 1/50\n",
      " - 0s - loss: 0.4980 - accuracy: 0.7807 - val_loss: 0.3214 - val_accuracy: 0.8817\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.2332 - accuracy: 0.9198 - val_loss: 0.4363 - val_accuracy: 0.8602\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.1915 - accuracy: 0.9305 - val_loss: 0.4733 - val_accuracy: 0.8710\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.1885 - accuracy: 0.9358 - val_loss: 0.3195 - val_accuracy: 0.8602\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.0940 - accuracy: 0.9626 - val_loss: 0.3112 - val_accuracy: 0.8925\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.1291 - accuracy: 0.9572 - val_loss: 0.2984 - val_accuracy: 0.8925\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.1462 - accuracy: 0.9572 - val_loss: 0.3633 - val_accuracy: 0.8817\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0926 - accuracy: 0.9626 - val_loss: 0.2673 - val_accuracy: 0.9032\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0440 - accuracy: 0.9947 - val_loss: 0.3041 - val_accuracy: 0.8925\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0312 - accuracy: 0.9893 - val_loss: 0.3352 - val_accuracy: 0.9032\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0531 - accuracy: 0.9786 - val_loss: 0.2448 - val_accuracy: 0.9462\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0488 - accuracy: 0.9840 - val_loss: 0.3514 - val_accuracy: 0.9032\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0310 - accuracy: 0.9840 - val_loss: 0.3546 - val_accuracy: 0.9032\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9140\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.4889 - val_accuracy: 0.9032\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0224 - accuracy: 0.9893 - val_loss: 0.4067 - val_accuracy: 0.8925\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0223 - accuracy: 0.9893 - val_loss: 0.3807 - val_accuracy: 0.9140\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0253 - accuracy: 0.9947 - val_loss: 0.3988 - val_accuracy: 0.8817\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.5881 - val_accuracy: 0.8925\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.5577 - val_accuracy: 0.8710\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.4437 - val_accuracy: 0.9140\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0480 - accuracy: 0.9840 - val_loss: 0.5477 - val_accuracy: 0.8602\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0275 - accuracy: 0.9893 - val_loss: 0.5430 - val_accuracy: 0.8817\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.8817\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0137 - accuracy: 0.9893 - val_loss: 0.5314 - val_accuracy: 0.8817\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0759 - accuracy: 0.9733 - val_loss: 0.4812 - val_accuracy: 0.9140\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0213 - accuracy: 0.9893 - val_loss: 0.6459 - val_accuracy: 0.9032\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.9032\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.9032\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 0.8925\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.9032\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0109 - accuracy: 0.9893 - val_loss: 0.6808 - val_accuracy: 0.9140\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.6451 - val_accuracy: 0.9032\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 0.9140\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.8925\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.8925\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8925\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.7014 - val_accuracy: 0.8925\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8925\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0247 - accuracy: 0.9893 - val_loss: 0.5683 - val_accuracy: 0.8925\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.8925\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5716 - val_accuracy: 0.8925\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5669 - val_accuracy: 0.8925\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 0.8925\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6210 - val_accuracy: 0.8925\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6297 - val_accuracy: 0.8925\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.8925\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.8925\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.8925\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3a902e7f28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_split=0.33, epochs=epochs, batch_size=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  3],\n",
       "       [ 1, 43]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3a80513b00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428571428571428"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.28571428571428"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
